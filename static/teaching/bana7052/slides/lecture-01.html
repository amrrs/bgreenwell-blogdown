<!DOCTYPE html>
<html>
  <head>
    <title>Association and Simple Linear Regression</title>
    <meta charset="utf-8">
    <meta name="author" content="Brandon M. Greenwell" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/hygge.css" rel="stylesheet" />
    <link rel="stylesheet" href="custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Association and Simple Linear Regression
## Lecture 01
### Brandon M. Greenwell
### 05 September, 2018

---




background-image: url(https://creativemaths.net/wp-content/uploads/2012/03/it_is_so_easy1-704x480.png)

???


---
class: inverse

# Reading assignment

.larger[

* Chapter: 1

* Sections: 1.1--1.8

* Main topics:

    - Association ðŸ˜´
    
    - Simple linear regression
  
]


---

# Prerquisites&lt;sup&gt;1&lt;/sup&gt;

.scrollable[


```r
# List of required (CRAN) packages
pkgs &lt;- c(
  "dplyr",    # for data wrangling
  "ggplot2",  # for awesome graphics
  "tibble"    # for nicer data frames
)

# Install required (CRAN) packages
for (pkg in pkgs) {
  if (!requireNamespace(pkg)) {  # check if already installed first
    install.packages(pkg)  # install it
  }
}

# Install additional (optional) awesomeness
install.packages(c("devtools", "magick"))
devtools::install_github("bgreenwell/roundhouse")
```

]

.footnote[
[1] I apologize now for the excessive amount of Chuck Norris gifs you will be subject to.
]


---

# Ready to begin?

--


```r
roundhouse::kick("Chuck Norris knows the last digit of pi", 
                 width = 50)
```

&lt;img src="lecture-01_files/figure-html/roundhouse-01-1.gif" width="70%" style="display: block; margin: auto;" /&gt;


---

# Read the ðŸ“–!

&lt;img src="images/read-the-book.jpg" width="50%" style="display: block; margin: auto;" /&gt;


---

# Statistical relationships

.scrollable[


```r
# Load required packages
library(ggplot2)
library(tibble)

# Generate some random data
set.seed(101)
d &lt;- tibble(
  x = seq(from = -2, to = 2, length = 100),
  y1 = 1 + x + rnorm(length(x)),
  y2 = 1 + x^2 + rnorm(length(x)),
  y3 = 1 + x^3 + rnorm(length(x)),
  y4 = 1 + rnorm(length(x))
)

# Construct scatterplots
p1 &lt;- ggplot(d, aes(x = x, y = y1)) +
  geom_point(alpha = 0.5) + 
  labs(y = "y", title = "Linear")
p2 &lt;- ggplot(d, aes(x = x, y = y2)) +
  geom_point(alpha = 0.5) + 
  labs(y = "y", title = "Quadratic")
p3 &lt;- ggplot(d, aes(x = x, y = y3)) +
  geom_point(alpha = 0.5) + 
  labs(y = "y", title = "Cubic")
p4 &lt;- ggplot(d, aes(x = x, y = y4)) +
  geom_point(alpha = 0.5) + 
  labs(y = "y", title = "None")

# Display plots in a grid
gridExtra::grid.arrange(p1, p2, p3, p4, ncol = 2)
```

]


---

# Statistical relationships

&lt;img src="lecture-01_files/figure-html/statistical-relationships-02-1.png" width="100%" style="display: block; margin: auto;" /&gt;


---

# Pearson correlation

&lt;img src="lecture-01_files/figure-html/pearson-correlation-01-1.png" width="100%" style="display: block; margin: auto;" /&gt;


---

# Pearson correlation

&lt;img src="lecture-01_files/figure-html/pearson-correlation-02-1.png" width="70%" style="display: block; margin: auto;" /&gt;


---

# Pearson correlation

* The (Pearson) correlation coefficient (also called the *Pearson product-moment correlation coefficient*) between two random variables `\(X\)` and `\(Y\)` is given by `\(Cor\left(X, Y\right) = \rho = Cov\left(X, Y\right) / \left(\sigma_X\sigma_Y\right)\)`

* Given a sample `\(\left\{\left(x_i, y_i\right)\right\}_{i=1}^n\)`, we estimate `\(\rho\)` with `\(r = S_{xy} / \sqrt{S_{xx}S_{yy}}\)`

  - Where, for example, `\(S_{xy} = \sum_{i=1}^n\left(x_i - \bar{x}\right)\left(y_i - \bar{y}\right)\)`


---

# Pearson correlation

* It is common to test the hypothesis `\(H_0: \rho = 0\)` vs. `\(H_1: \rho \ne 0\)`

    - Rejecting `\(H_0\)` is only evidence that `\(\rho\)` is **not exactly zero**

    - A *p*-value **does not measure the magnitude of the (linear) association**

    - Sample size affects the p-value! ðŸ˜±

* There is a formal relationship between Pearson's correlation and the *simple linear regression* (SLR) model

    - Simple linear relationships can be described by a *slope* and *intercept*


---

# Cautions in interpretting correlation(s)

* Correlation between `\(X\)` and `\(Y\)` does not imply causation

    - It does not imply the direction of any possible **causal relationship** between `\(X\)` and `\(Y\)`
    
    - There might be a third (*lurking*) variable that is the cause of changes in both variables (i.e., the association between `\(X\)` and `\(Y\)` might be indirect)
    
* The Pearson correlation only measures the **linear association **between `\(X\)` and `\(Y\)`


---

# Correlation does NOT imply causation

* [Correlation and uncontrolled experiments](https://imgur.com/gallery/uBSTj2a)

* [Other examples](http://www.tylervigen.com/spurious-correlations)


---

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="images/correlation-causation-comic.png" alt="If you get the joke in this comic, then you probably undestand enough about correlation!" width="70%" /&gt;
&lt;p class="caption"&gt;If you get the joke in this comic, then you probably undestand enough about correlation!&lt;/p&gt;
&lt;/div&gt;


---

# Which of the following statement(s) is/are true?

a. The Pearson correlation coefficient is a measure of linear association

b. A non-significant *p*-value for a Pearson correlation means no relationship

c. A negative Pearson correlation indicates a low degree of linear association

d. A random cloud of data implies a negative correlation.


---

# Which of the following statement(s) is/are true?

a. **The Pearson correlation coefficient is a measure of linear association**

b. A non-significant *p*-value for a Pearson correlation means no relationship

c. A negative Pearson correlation indicates a low degree of linear association

d. A random cloud of data implies a negative correlation.


---
class: inverse, center, middle

### "All models are wrong, but some are useful."

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="images/george-box.jpg" alt="George E. Box" width="40%" /&gt;
&lt;p class="caption"&gt;George E. Box&lt;/p&gt;
&lt;/div&gt;


---

# Historical origins of regression

* First developed by Sir Francis Galton in the later part of the 19th century

* Studied heights of parents and their children

* Noted that the heights of children with tall/short parents tended to "revert" or "regress" to the mean of the group

* The term "regression" persists to this day!


---

# Historical origins of regression


```r
install.packages(c("ggplot2", "HistData"))
library(ggplot2)
ggplot(HistData::Galton, aes(x = parent, y = child)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") + 
  labs(x = "Height of mid-parent (in)", y = "Height of child (in)")
```


---

# Historical origins of regression

&lt;img src="lecture-01_files/figure-html/galton-02-1.png" width="70%" style="display: block; margin: auto;" /&gt;


---

# Functional relationships

&lt;img src="lecture-01_files/figure-html/functional-relation-1.png" width="70%" style="display: block; margin: auto;" /&gt;


---

# Statistical relationships

&lt;img src="lecture-01_files/figure-html/linear-relationships-1.png" width="70%" style="display: block; margin: auto;" /&gt;


---

# Examples of statistical relationships

* Simple linear regression (SLR)

    - `\(Y = \beta_0 + \beta_1 X + \epsilon\)`
    
* Multiple linear regression (MLR)

    - `\(Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p + \epsilon\)`
    
    - `\(Y = \beta_0 + \sum_{i=1}^p \beta_p X_p + \epsilon\)`
    
 * Polynomial regression (of degree `\(p\)`)

    - `\(Y = \beta_0 + \sum_{i=1}^p \beta_p X^p + \epsilon\)`   

 * Nonlinear regression

    - `\(Y = \frac{\beta_1 X}{\beta_2 + X} + \epsilon\)`   


---

# Still with me?

--


```r
roundhouse::kick("Chuck Norris caught all the Pok\uE9mon from a landline",
                 width = 40, type = 2, fps = 10)
```

&lt;img src="lecture-01_files/figure-html/roundhouse-02-1.gif" width="70%" style="display: block; margin: auto;" /&gt;


---

# Simple linear regression (SLR)

* Data: `\(\left\{\left(X_i, Y_i\right)\right\}_{i=1}^n\)`

* Model: `\(Y_i = \beta_0 + \beta_1 X_i + \epsilon_i\)`

    - `\(Y_i\)` is a continuous response

    - `\(X_i\)` is a continuous predictor

    - `\(\beta_0\)`  is the intercept of the regression line (also called the *bias term*)

    - `\(\beta_1\)`  is the slope of the regression line
    
    - `\(\epsilon_i \sim iid \left(0, \sigma^2\right)\)`


---

# Assumptions about the errors

* For `\(i/j = 1, 2, \dots, n\)`

    1. `\(\quad E\left(\epsilon_i\right) = 0\)`

    2. `\(\quad Var\left(\epsilon_i\right) = \sigma^2\)` (homoscedacticity ðŸ˜±)

    3. `\(\quad Cov\left(\epsilon_i, \epsilon_j\right) = 0\)` (independence)
    
* Assumptions 1.--3. can be summarized as `\(\epsilon_i \sim iid \left(0, \sigma^2\right)\)`
    

---

# Properites of SLR

* Simple linear regression: `\(Y_i = \beta_0 + \beta_1 X_i + \epsilon_i\)`

    - Implies the model is **linear in the regression coefficients `\(\beta_0\)` and `\(\beta_1\)`**
    
* The error term is a random variable; hence, `\(Y_i\)` is also a random variable (**Why?** ðŸ¤”)

    - What is `\(E\left(Y_i|X_i\right)\)` and `\(Var\left(Y_i|X_i\right)\)`?
    
* `\(Cor\left(Y_i, Y_j\right) = 0\)` `\(\forall i \ne j\)` (**Why?** ðŸ¤”)


---

# The SLR model with normal errors

$$
Y_i = \beta_0 + \beta_1 X_i + \epsilon_i, \quad i = 1, 2, \dots, n
$$

&lt;br/&gt;

where `\(\epsilon_i \stackrel{iid}{\sim} N\left(0, \sigma^2\right)\)`, is equivalent to

&lt;br/&gt;

$$
Y_i \stackrel{iid}{\sim} N\left(\beta_0 + \beta_1 X_i, \sigma^2\right), \quad i = 1, 2, \dots, n
$$

* `\(\mu_i = \beta_0 + \beta_1 X_i\)` is called the *linear predictor* (LP)


---

# Interpretting the regression coefficients

* `\(\beta_0\)` is the *y*-intercept (or *bias term*)

    - It represent the mean response when `\(X = 0\)`; that is `\(\beta_0 = E\left(Y|X = 0\right)\)`

    - In general, the intercept is of little practical interest (this is especially true in MLR or when zero is not a valid value of `\(X\)`)

* `\(\beta_1\)` is the slope of the regression line

    - The slope of a line represents a *rate of change*
    
    - It represents the change in the mean response per one-unit increase in `\(X\)`


---

&lt;img src="images/slr-conditional-distribution.png" width="70%" style="display: block; margin: auto;" /&gt;


---

&lt;img src="lecture-01_files/figure-html/arsenic-conditional-distribution-1.png" width="70%" style="display: block; margin: auto;" /&gt;
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
